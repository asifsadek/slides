<!DOCTYPE html>
<html>
  <head>
    <title>Parallel Matrix Chain Multiplication</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif);
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body {
        font-family: 'Droid Serif', 'Microsoft JhengHei';
      }
      h1, h2, h3 {
        font-family: 'Droid Serif', Helvetica, 'Yanone Kaffeesatz', 'Microsoft JhengHei';
        font-weight: 400;
        margin-bottom: 0;
      }
      .remark-slide-content {background: #272822; color: white; }
      .remark-slide-content h1 { font-size: 3.5em; }
      .remark-slide-content h2 { font-size: 2.5em; }
      .remark-slide-content h3 { font-size: 2em; }
      .remark-slide-content p { font-size: 1.3em; }
      .remark-slide-content blockquote { border-left: 5px solid rgba(152,232,99,0.8); margin: 0.65em 0 0.65em 4%; padding-left: 1%; padding-right: 1%; }
      .remark-slide-content img { max-width: 90%; max-height: 400px; }
      .remark-slide-content table { border: 1px solid #696969; width: 100%; margin: 1px;}
      .remark-slide-content table thead { font-family: "Times New Roman"; }
      .remark-slide-content table th, .remark-slide-content table td, .remark-slide-content table tr  { padding: 1px 2px; border: 1px solid #696969; }
      .remark-slide-content table tbody { font-family: "Ubuntu Mono"; }
      .remark-slide-content .big { font-size: 2em; }
      .remark-slide-content .small-image { max-width: 50%; }
      .remark-slide-content strong {color: red;}
      .white-background {background: white;}
      .white-background {color: black;}
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      li p { line-height: 1.5em; }
      .red { color: #fa0000; }
      .large { font-size: 2em; }
      a, a > code {
        color: rgb(249, 38, 114);
        text-decoration: none;
      }
      code {
/*        background: #e7e8e2;*/
        border-radius: 5px;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-code-line-highlighted     { background-color: #373832; }
      .pull-left {
        float: left;
        width: 47%;
      }
      .pull-right {
        float: right;
        width: 47%;
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .inverse {
        background: #272822;
        color: #777872;
        text-shadow: 0 0 20px #333;
      }
      .inverse h1, .inverse h2 {
        color: #f3f3f3;
        line-height: 0.8em;
		font-size: 2em;
      }

      /* Slide-specific styling */
      #slide-inverse .footnote {
        bottom: 12px;
        left: 20px;
      }
      #slide-how .slides {
        font-size: 2em;
        position: absolute;
        top:  151px;
        right: 140px;
      }
      #slide-how .slides h3 {
        margin-top: 0.2em;
      }
      #slide-how .slides .first, #slide-how .slides .second {
        padding: 1px 20px;
        height: 90px;
        width: 120px;
        -moz-box-shadow: 0 0 10px #777;
        -webkit-box-shadow: 0 0 10px #777;
        box-shadow: 0 0 10px #777;
      }
      #slide-how .slides .first {
        background: #fff;
        position: absolute;
        top: 20%;
        left: 20%;
        z-index: 1;
      }
      #slide-how .slides .second {
        position: relative;
        background: #fff;
        z-index: 0;
      }

      /* Two-column layout */
      .left-column {
        width: 48%;
        height: 92%;
		float: left;
      }
        .left-column h2:last-of-type, .left-column h3:last-child {
          color: #000;
        }
      .right-column {
        width: 48%;
		float: right;
      }
    </style>
  </head>
  <body>
    <textarea id="source">

title: Parallel Matrix Chain Multiplication
class: center, middle

## Parallel 

## Matrix Chain Multiplication

### 平行矩陣鏈乘積

R04922067 楊翔雲, Morris

NTU CSIE

---

## 矩陣鏈乘積 ##

* 給 `\(N\)` 個矩陣 `\(M_0, M_1, \cdots, M_{N-1}\)`

* 大小分別為 `\(a_0 \times a_1\)`、`\(a_1 \times a_2\)` ... `\(a_{N-1} \times a_N\)`

* 求最少乘法次數

### 範例 ###

三個矩陣 `\(A_{10, 30}\)`, `\(B_{30, 5}\)`, `\(C_{5, 60}\)`

* `\((AB)C\)` 的乘法次數為 `\(10 \times 30 \times 5 + 10 \times 5 \times 30 = 4500\)`
* `\(A(BC)\)` 的乘法次數為 `\(30 \times 5 \times 60 + 10 \times 30 \times 60 = 27000\)`

---

## 計算最少次數 ##

定義 `\(m[i, j]\)` 表示從矩陣 `\(M_i M_{i+1} \cdots M_j \)` 的最少乘法次數

### 經典合併的動態規劃問題 ###

* `\(m[i, j] = 0 \textit{, if } i=j\)`

* `\(m[i, j] = \max\limits_{i\le k < j} (m[i,k] + m[k+1, j] + c(i, k, j)) \textit{, if } i < j\)`

* 時間複雜度 `\(O(N^3)\)`

> 套用在此問題  
> **矩陣鏈乘積最少次數**理論複雜度為 `\(O(N \log N)\)`

---

## C - Implementation ##

從區間長度 `\(i = 1, 2, 3, \cdots, N\)` 解起，得到下述程序

```c
for (int i = 1; i <= N; i++) {
    for (int j = 0; j < N-i; j++) {
        int l = j, r = j+i;
        long long local = INF;
        for (int k = l; k < r; k++) {
            long long t = dp[l*N+k] + dp[(k+1)*N+r] + SZ[l] * SZ[k+1] * SZ[r+1];
            if (t < local)
                local = t;
        }
        dp[l*N+r] = local;
    }
}
```

---

## Dependency ##

* `\(m[i, j]\)` 的計算依賴 
  * `\(\forall \; i \le k < j, m[i, k] \rightarrow m[i, j]\)`

  * `\(\forall \; i < k \le j, m[k, j] \rightarrow m[i, j]\)`

* Critical Path 的長度至少為 `\(N\)`

---

## Parallel Algorithm ##

```c
#pragma omp parallel
for (int i = 1; i <= N; i++) {
    #pragma omp for
    for (int j = 0; j < N-i; j++) {
        int l = j, r = j+i;
        long long local = INF;
        for (int k = l; k < r; k++) {
            long long t = dp[l*N+k] + dp[(k+1)*N+r] + SZ[l] * SZ[k+1] * SZ[r+1];
            if (t < local)
                local = t;
        }
        dp[l*N+r] = local;
    }
}
```

* `\(O(N^3/p + N^2)\)`, 其中 `\(p\)` 為處理器數量

---

## Memory Access ##

* 當 `\(N\)` 超過 1024 時，易觸發 Cache miss

* 左上角為所求的 `\(m[i, j]\)`，其合併操作需要存取的元素 **不連續**

.center[![](./images/fig-origin.PNG)]

---

## Mind the Cache ##

* 為了解決上述的問題，儲存答案 `\(m[i,j] = m[j, i]\)`

* 合併操作皆為讀取**連續的**元素

.center[![](./images/fig-improve-mem.PNG)]

---

## Improve Algorithm ##

```c
#pragma omp parallel
for (int i = 1; i <= N; i++) {
    #pragma omp for
    for (int j = 0; j < N-i; j++) {
        int l = j, r = j+i;
        long long local = INF;
        for (int k = l; k < r; k++) {
            long long t = dp[l*N+k] + dp[r*N+(k+1)] + SZ[l] * SZ[k+1] * SZ[r+1];
            if (t < local)
                local = t;
        }
        dp[l*N+r] = dp[r*N+l] = local; // important
    }
}
```

* 每一格元素儲存 1 次、讀取 `\(O(N)\)` 次

* 儲存發生 cache miss，降低讀取發生的 cache miss

---

## Is that All?  ##

* 時間複雜度 `\(O(N^3/p + N^2)\)`

* 大部分 cache miss 問題已解決？
  * 編譯器優化技術，誘發數據重用性、指令平行

  * loop tiling (loop blocking/strip mine and interchange)

  * loop unrolling (unwinding)

* 處理器再怎麼多都只有 `\(O(N^2)\)`？  
  * 下一階段，將介紹時間複雜度 `\(O(N^3/p + N^{\log_2 3})\)`

---

## Recursive Decomposition ##

* 在循序算法下
  * 相同時間複雜度

  * 遞迴設計有較好的 **時間局部性 (temporal locality)**

  * 易於撰寫且代碼複用 (code reuse) 機會高

* 在平行環境下
  * 更高的平行度

  * **易於撰寫？**

---

## Recursion - OpenMP ##

* 至今所描述的 OpenMP 語法不易在遞迴上操作
  * `#pragma omp for`

  * `#pragma omp section`

  * ... 等

* 也許可以手動展開？不確定的條件遞迴－無法明確展開
  * 模擬遞迴呼叫，將函數的傳遞狀態儲存到佇列中

  * 設定彼此之間的相依關係

---

## OpenMP ##

* OpenMP 3.1 - 2011, GCC 4.7

* OpenMP 4.0 - 2013, GCC 4.9

* OpenMP 4.5 - 2015, GCC 6.1

### Check OpenMP Version ###

```bash
echo | cpp -fopenmp -dM | grep -i open
```

---

## 多版本共存 ##

```bash
echo | cpp-4.9 -fopenmp -dM | grep -i open
echo | cpp-5 -fopenmp -dM | grep -i open
echo | cpp-6 -fopenmp -dM | grep -i open
...
```

### Avoid `#pragma` unused ###

使用新的語法，實際上不支援卻仍然可以編譯通過

加入 `-Wall`，若 `#pragma` 沒有生效，就會在這裡顯示。

```bash
gcc -Wall ...
```

---

## OpenMP - task ##

```c
#pragma omp task [clause[ [, ]clause] ...]
```

clause:

* `if([ task : ] scalar-expression)`
* `final(scalar-expression)`
* `untied`
* `default(shared | none)`
* `mergeable`
* `private(list)`
* `firstprivate(list)`
* `shared(list)`
* `depend(dependence-type: list)`
* `priority(priority-value)`

---

## OpenMP - task ##

.left-column[
```c
#pragma omp parallel num_threads(4)
{
    #pragma omp master
    {
      for (int i = 0; i < 5; i++) {
          #pragma omp task
          help(i);
      }
      #pragma omp taskwait
    }
}
```
] .right-column[
![](./images/fig-taskflow.PNG)
]

---

## Recursion - First Step ##

回到之前的合併動態規劃，原問題拆成四個象限分開求解

所求部分為上三角

.center[![](./images/fig-recursive.PNG)]

---

## Recursion - Second Step ##

切成四個象限，合併操作分成兩種型

`\(X\)` 為所求，`\(U, V\)` 為已知

.left-column[
  .center[![](./images/fig-typeB.PNG)]
] .right-column[
  .center[![](./images/fig-typeC.PNG)]
]

---

## Implementation ##


.left-column[
```c
void A_par(X ◥) {
    #pragma omp task
    A_par(X(1, 1))
    #pragma omp task
    A_par(X(2, 2))
    #pragma omp taskwait
    B_par(X(1, 2), X(1, 1), X(2, 2))
}
void B_par(X ■, U ◥, V ◥) {
    B_par(X(2, 1), U(2, 2), V(1, 1))

    #pragma omp task
    C_par(X(1, 1), U(1, 2), X(2, 1))
    #pragma omp task
    C_par(X(2, 2), X(2, 1), V(1, 2))
    #pragma omp taskwait

    #pragma omp task
    B_par(X(1, 1), U(1, 1), V(1, 1))
    #pragma omp task
    B_par(X(2, 2), U(2, 2), V(2, 2))
    #pragma omp taskwait

    C_par(X(1, 2), U(1, 2), X(2, 2))
    C_par(X(1, 2), X(1, 1), V(1, 2))
    C_par(X(1, 2), U(1, 2), V(2, 2))
}
```
] .right-column[
```c
void C_par(X ■, U ■, V ■) {
    #pragma omp task
    C_par(X(1, 1), U(1, 1), V(1, 1))
    #pragma omp task
    C_par(X(1, 2), U(1, 1), V(1, 2))
    #pragma omp task
    C_par(X(2, 1), U(2, 1), V(1, 1))
    #pragma omp task
    C_par(X(2, 2), U(2, 1), V(1, 2))
    #pragma omp taskwait

    #pragma omp task
    C_par(X(1, 1), U(1, 2), V(2, 1))
    #pragma omp task
    C_par(X(1, 2), U(1, 2), V(2, 2))
    #pragma omp task
    C_par(X(2, 1), U(2, 2), V(2, 1))
    #pragma omp task
    C_par(X(2, 2), U(2, 2), V(2, 2))
    #pragma omp taskwait
}
```
]

---

## Implementation - More ##

處理器個數不多，降低 thread create/destroy 次數

.left-column[
```c
void A_par(X ◥) {
    #pragma omp task
    A_par(X(1, 1))
    #pragma omp task
    A_par(X(2, 2))
    #pragma omp taskwait
    B_par(X(1, 2), X(1, 1), X(2, 2))
}
void B_par(X ■, U ◥, V ◥) {
    B_par(X(2, 1), U(2, 2), V(1, 1))

    #pragma omp task
    C_par(X(1, 1), U(1, 2), X(2, 1)),
      B_par(X(1, 1), U(1, 1), V(1, 1))
    #pragma omp task
    C_par(X(2, 2), X(2, 1), V(1, 2)), 
      B_par(X(2, 2), U(2, 2), V(2, 2))
    #pragma omp taskwait

    C_par(X(1, 2), U(1, 2), X(2, 2))
    C_par(X(1, 2), X(1, 1), V(1, 2))
    C_par(X(1, 2), U(1, 2), V(2, 2))
}

```
] .right-column[
```c
void C_par(X ■, U ■, V ■) {
    #pragma omp task
    C_par(X(1, 1), U(1, 1), V(1, 1)),
      C_par(X(1, 1), U(1, 2), V(2, 1))
    #pragma omp task
    C_par(X(1, 2), U(1, 1), V(1, 2)),
      C_par(X(1, 2), U(1, 2), V(2, 2))
    #pragma omp task
    C_par(X(2, 1), U(2, 1), V(1, 1)),
      C_par(X(2, 1), U(2, 2), V(2, 1))
    #pragma omp task
    C_par(X(2, 2), U(2, 1), V(1, 2)),
      C_par(X(2, 2), U(2, 2), V(2, 2))
    #pragma omp taskwait
}
```
]

---

class: center, middle

## 實戰 GO! ##

[10116. Fast Dynamic Programming Computing I](https://judgegirl.csie.org/problem/0/10116)

![](./images/go.gif)

「GO!ヽ(꒪д꒪)ノ 」－《賣房子的女人》

---

## taskwait vs taskgroup ##

### taskwait ###

* 同步當前程序的所有 **子程序**

* 若在 `helper(i)` 中，再次使用 task 且沒有使用 `taskwait` 

* 無法確定離開 `f()` 後，`something()` 是否已經完成

.left-column[
```c
void f() {
    #pragma omp task
      helper(0);
    #pragma omp task
      helper(1);
    #pragma omp taskwait
}
```
] .right-column[
```c
void hepler(int i) {
    ...
    #pragma omp task
      something()
    ...
}
```
]

---

## taskwait vs taskgroup ##

### taskgroup ###

* 相對於 `taskwait`，同步當前程序的所有 **子程序** (遞迴地)

* 確保離開 `taskgroup` 後，`something()` 已經完成

.left-column[
```c
void f() {
    #pragma omp taskgroup
    {
      #pragma omp task
        helper(0);
      #pragma omp task
        helper(1);
    }
}
```
] .right-column[
```c
void hepler(int i) {
    ...
    #pragma omp task
      something()
    ...
}
```
]

---

## taskloop ##

> 為什麼不直接加 `#pragma omp for`  
> `master` 裡面使用 `#pragma omp for`，將會得到錯誤訊息

```bash
error: ‘master’ region may not be closely nested inside of work-sharing ...
```

覺得一行一行寫出來不好維護？

使用 `#pragma omp taskloop` 幫你達到目的 (>= OpenMP 4.5)

```c
#pragma omp parallel
{
    #pragma omp master
    {
        #pragma omp taskloop grainsize(1) // instead of 
        for (int i = 0; i < 5; i++) {
            help(i);
        }
    }
}
```

---

## taskloop nowait ##

* `#pragma omp for nowait` 

* 對應 `#pragma omp taskloop nogroup`

### Sparse Matrix Multiplication ###

`\(A \times B = C\)`

```c
#pragma omp parallel num_threads(24)
#pragma omp single
for (int i = 0; i < ma; i++) {  /* ma = #different row of A */
    #pragma omp taskloop firstprivate(i) grainsize(1024) nogroup
    for (int j = 0; j < mb; j++) { /* mb = #different column of B */
        /* merge operation to compute C(p, q) */
    }
}
```

---

class: center, middle

## 實戰 GO! ##

[10087. Sparse Matrix Multiplication](https://judgegirl.csie.org/problem/0/10087)

![](./images/go.gif)

「GO!ヽ(꒪д꒪)ノ 」－《賣房子的女人》

---

## 後記 - 1 ##

* 以目前看來，不平行就能快上兩倍

* Threshold 很重要，適當大小就退回循序算法

* [10087. Sparse Matrix Multiplication](https://judgegirl.csie.org/problem/0/10087)   
的作法有兩種，常數空間和線性空間。
  * 常數空間在一般教科書上可以找到，效能比下述的的差

  * 線性空間來自於大陸某篇論文，效能較好

---

## 後記 - 2 ##

* 在 Ubuntu 14.04 上使用 gcc 4.8, 4.9, 5, 6 的版本
  * **相同的參數** 編譯

  * 越新版的執行效能越差

  * 原因不明，需要確定編譯器優化策略的改變

  * 實驗時需注意要在 **同一版編譯器** 下比較效能

---

## Reference ##

* Jesmin Jahan Tithi, Pramod Ganapathi, Aakrati Talati, Sonal Aggarwal, Rezaul Chowdhury, "High-perofrmance Energy-efficient Recursive Dynamic Programming with Matrix-multiplication-like Flexible Kernels", 2015, IPDPS



    </textarea>
	<script src="./javascripts/remark-latest.min.js" type="text/javascript"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML&delayStartupUntil=configured" type="text/javascript"></script>
    <script type="text/javascript">
      var slideshow = remark.create();

      // Setup MathJax
      MathJax.Hub.Config({
          tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
          }
      });
/*
      MathJax.Hub.Queue(function() {
          MathJax.Hub.getAllJax().map(function(index, elem) {
              return(elem.SourceElement());
          }).parent().addClass('has-jax');
      });
*/
      MathJax.Hub.Configured();
    </script>
  </body>
</html>
